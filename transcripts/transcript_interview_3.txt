Transcript: Developer Interview #3(Interviewee does not want to be directly quoted)00:00:19 Q: Thank you very much. So first I would like to start maybe with some background question if it's allowed then.00:00:28 A: Sure.00:00:29 Q: And then I would go into a discussion of general procedure of creating tests and then afterwards we would discuss test effectiveness.00:00:45 Q: So maybe first of all, could you tell me a little bit about yourself, about your background as a developer and your workplace.00:00:56 A: [hidden for double blind] my main occupation now is PhD student, but I also work actually full time in the industry at [hidden for double blind] as a researcher. Before this I spent about two years combined in software engineering master at [hidden for double blind] working on software engineering tools. So, I'm pretty creative in the context of coding for all of my career.00:01:42 A: And that's pretty much it. So, I'm doing research in university now and I'm trying to finish my thesis on the side. [...]00:02:24 Q: Very interesting. So, and maybe also your experience as a developer how many years are you experienced approximately?00:02:40 A: That depends on what you count, do you count academic coding as years of experience?00:02:47 Q: Let's stick to the industrial experience as you said, but maybe I would count that too00:02:55 A: I would say I wrote my first production/actual Java code in 2013, working as a quality assurance automation engineer. So, I've been actually writing this memory for it is the machine count a corporate job. Then I've been on over the last since I've been to be a dissident, I think I didn't do a lot of industrial coding, because it's mostly made through internal code and stuff. When we think about quality in the same way it's in the production system incorporated someone.00:03:46 Q: Ok, then let's move on to a discussion about the process of creating test cases. Maybe first of all, do you have a general procedure that you follow when creating test case or, well when I say test case, we limit it to unit testing00:04:07 A: All right, so within unit testing usually it's one of the two things: Either I found a bug which I want to fix and approach that by writing test that covers this. And if I understand the nature of the bug already, I write a few tests which were other cases and then I just want to all I need to do to fix those bugs is to fix those tests.00:04:40 A: Also, I'm a fan of test-driven development. I know there is there is an almost religious movement where they write goals and guidelines first write this then make tests green then refactor better.00:04:59 A: So, it makes sense. But I don't think of it as a procedure I should follow but rather ... so I know I'm building like say a module or something and that's something if I have an idea of what it should do then I will always write that beforehand, so it serves two purposes: First, actually if it depends on many other things then I'll sleep better knowing if I break it I know it. And also you know it's a bit of like turning the jug around, so all you have to do is to make tests green, which is going to make things easier and you just don't think a lot about how much you have left as such... it's sort of like a game.00:05:54 Q: So, do you also use the tests maybe as your direct requirements or do you not follow that.00:06:09 A: No, I don't think of it in this way. But if you consider the way I actually write tests before any code and writing this down which I'll leave, well you can you can say so. [...]00:07:42 Q: What do you think about the scope of a test case: Do you think it should always cover one possible use case or one possible branch in a program or do you think it should cover maybe all different scenarios.00:08:02 A: That depends on the context very much and also on the purpose of the tasks and the program. Let me give you an example: Of course, you know it sounds as if it was always better to cover one branch per test so that you know exactly what the problem is and you can fix it. In many cases it's a lot of work to cover it and plus it's a lot of support work because if your behavior changes then you have all the burden of changing tests. So, say I'm writing something for write my PhD research and I want to download some data, jiggle it somehow and then load it out and maybe complete something. Right so it's very data intensive. And it does nothing but compilations that nobody really cares about the structure etc. but still I need tests because otherwise I'll be uncertain if my data is not right.00:09:20 A: So, for that I very often I just think of a bunch of outputs that I put in output pairs and I can put them in the same test case, much like general sanity tests or something. So, I think it's appropriate here because your priorities are a bit different right? It's not supposed to be maintainable, but it's supposed to be reasonably reliable. So, then it makes sense to save time.00:09:56 Q: OK. And do you do you always aim to cover all possible scenarios, or do you settle in with maybe the most common 90 percent or whatever.00:10:11 A: Well I actually don't even use coverage like so far mostly for the code I write lately.eA: Right. If you speak of industrial projects that work on those have been set up way before me and usually have their own rules maybe, but I'm not aiming at a particular coverage. So, I'd say like difficult code that I write from start to the end which is usually some kind of data manipulation code I use a combined approach and have some unit tests. But I also I looked at the output with my eyes to see whether it's a right or not if I see a bug then I write a test because I made a bug. So now I have a very informal approach to this.00:11:05 Q: So your approach of writing test cases changes very much depending on what kind of system you're testing.00:11:13 A: Sure sure. Yeah.00:11:16 Q: OK. Then you said that you don't really use test coverage. Do you use any order testing libraries or metrics to assess your state of your testing phase?00:11:32 A: "Well I use JS. I use it mostly for golden good writing and reading. Gentlemen I know it's generates reports which can be integrated into circuits CI or something." That's usually in many cases I developed this software on my own so I don't need to share any one hour or so. I just have to states whether it fails or it passes. So, let's say I'm a very basic user.00:12:15 Q: So, to assess if you have covered all edge cases you just do it by yourself or do you rely on the code review that they may say if you haven't covered everything?00:12:39 A: Usually just do it by myself or decide whether it's reasonably tested.00:12:50 A: OK so what I like about unit tests is that, you can also think of a unit as the larger unit we should look sometimes. Right. That's such situations. It's a rubber around the whole data pipeline then I give some input and it see what the output is. [...]00:13:14 A: To be more precise. Well I have this library which calculates bots in the ASD. So basically, you have a pretty large tree and then it means to return all bots in this tree which meet certain criteria I just use some combinatorics to calculate the right number I should check. So, in that sense It's also like testing the edge cases.00:13:51 A: But generally, I don't. I don't try to cover all the parts because I think mostly, I think it's not a reasonable way to ensure its quality for what it is.00:14:10 Q: So then let's move on to the discussion about test effectiveness. Maybe first of all: How do you define for yourself the term test effectiveness00:14:23 A: Ok so a test is effective if it makes sense and often helps. Right. So, for the kind of testing that I mentioned which I writes when you see a bug or when you want to implement something. It's pretty much once they are green, they already did their job and they have been effective. So, they have sort of a general purpose and a goal to fulfill. Which indicates whether you did your job or not.00:15:18 A: Well once a test triggers it's effective because it's indicates something, so I'd say that the most effective ones are those that actually show the regression. So, there are many ways to write a test... so if you think that impactive test are some protective test may fail even if the code that has been modified before he failed is not covered directly by them.00:16:16 Q: What do you mean by that?00:16:18 A: I mean that's some parts and triggered by a changing dependency.00:16:29 Q: Right. Yes.00:16:31 A: Those seem like a bit more effective, because they're a bit more sensitive because there is way more ways in which they can fail, but then those are not always just unit test for example on the large web services use different techniques for that kind of test right?00:16:50 Q: Yes. Yeah.00:16:56 A: Again, it's very hard to compare because a test is either effective or useless so...00:17:03 Q: Maybe in the general literature it's also defined/quantified by how many faults it can detect in the system. But that also often depends on what strategy you are using to create test cases. Right?00:17:26 A: True.00:17:27 Q: So maybe if you also aim to cover only one scenario in a unit test then it can either detect this fault or not and it won't be more effective at detecting other cases because it's not it's not checking for them.00:17:57 A: So again, an effective test should provide us as much value as possible with as little effort as possible. All right so I can easily tell what is not an effective test for example a flaky test which the depends on some random external things and is flaky is usually not very effective because it just eats a lot of resources for the team to fix it.00:18:35 Q: So, it should generally be a short and easy to understand test case that doesn't implement any logic by itself?00:18:46 A: Well of course not. It should be simple. So again, quite some test cases contain some setup. [...]00:19:10 A: Also, I can also think of the situation where there is system that pretty much works and then someone implements a test for this system that they know its logic instead. So, they think it's more secure now, but actually it's just as secure until it has been modified the next time. So, if it does end up green once it's probably arguably it's less effective test.00:19:50 Q: What are some indicators that make you assess the effectiveness of a test. Maybe from the source code do you maybe look at the code of the test case and say well an effective test has to be well readable and has to tell you what it is testing, or where do you look at the test case?00:20:48 A: Well yeah of course if the test is very concise and I can tell what it does since it has a concise name so it's very clear from its very short method body what it does. Then of course it's a bit easier for me to handle if I have to handle it instead of some large, complex test case. This test case might not be the most effective one because if you have a choice either writing 100 very simple test cases or letting two very complex ones which still cover the same amount they would have just enough data in different ways so I can think of such a situation. In the latter case it might be worth the effort.00:21:43 Q: Then they may be more difficult to maintain.00:21:52 A: Maybe, but they also may be easier to maintain because if he had had to change of behavior then it's easier to modify one test.00:22:06 Q: Yeah. It always has some drawbacks.00:22:11 A: Yeah. I remember in one of my jobs it has been a burden too. I've been changing the logic of the very low-level system which was just about a database to retrieve some data. So, when you find this logic in very minor ways on the worst part which I hated to rewrite tests that had been written by someone else. That’s also something to consider.00:22:44 Q: And why did you hate it? Was it just because it was implemented by someone else and you didn't really understand what it does or?00:23:01 A: Of course, is a vigorous page and it just felt like an extra work, I guess. But the point is because it's a very low level, high load system so it's something you really need to bring together very good. [...]00:23:41 Q: So, what do you usually do if you see that a test case that previously didn't fail, fails now suddenly? Do you mainly look at the production code or do you first look at the tests and change the test?00:24:10 A: I probably look at test first. So, before I change anything, I need to figure out what the problem is and if there is there is a bug somewhere. I'd say if I write a bunch of tests then I run it for the first time. Then if one of them failed, the first thing I check is the test code.00:24:40 Q: OK then. Makes sense. You mentioned it but do you also check for flakiness and run tests multiple times?00:24:54 A: No, not for the current code I work on. But I had to deal with flaky test a few times, even in larger systems. But we didn't use any checks for flakiness. So, it was the case when we used the continuous integration server right where you could just mark flaky tests and then would not fail to build.00:25:36 Q: And what about test smells, do you also generally check for test smells or maybe also if you're doing code reviews?00:25:44 A: No.00:25:49 Q: Ok, why so?00:25:53 A: The whole concept you know it's unclean, it's not mature enough to really consider it in the guideline. Plus, usually I don't need it.00:26:08 Q: OK. So, do you have very well-defined code guidelines that you have to follow?00:26:15 A: No, that's the thing you know most of the code I write is so low grade, it’s basically throwaway code, which has to work reasonably well exactly once. 00:26:57 Q: How do you usually verify that your test cases are behaving correctly? Or do you usually encounter that and just say well I only write very easy and short test cases and thus they don't have a lot of logic? Also, not in the setup maybe that they always should behave correctly? or do you apply coding techniques to check for that?00:27:30 A: No, I don't I don't really think about that. Usually my tests are not too complex for me to try and not to capture everything they do in my head.00:27:50 Q: Maybe for the production code: Do use maybe pre and post condition to verify different steps of a function?00:28:07 A: No, I use a lot of you know set up and slide down things because sometimes I need to spin up very bulky pieces of environment. No, I do not use any pre checks.00:28:25 Q: like Do you have any other source code metrics or other metrics that you look at to assess the effectiveness of a test case.00:28:42 A: Source code metrics?00:28:44 Q: Maybe things like the readability where you check for the naming for example.00:28:53 A: No, I don't use those things. Most of the things I work on is just one or two people working on anything. Well of course I even am the one pushing it for a clean code style. But I don't really believe readability metrics as a proxy for the effectiveness of a test.00:29:23 Q: OK. So how else would you assess the effectiveness of a test?00:29:32 A: Look at the history of its failures. Look at the history of fixes to those failures. Whether those things are related to any serious bugs and such bias incorrectly.00:29:56 Q: If a test case failed, how do you make sure that you find the cause very quickly? Do you use anything in the code or in the tests? Or maybe you look specific things that help you finding the fault quickly?00:30:17 A: I'm a big fan of the debugger. I usually debug.00:30:27 A: I'm not looking to fix it quickly but rather I want to make sure I understand what exactly happened. [...]00:31:14 Q: Do you usually have certain guidelines for creating test cases, such that they all look similar?00:31:29 A: No, neither is the case in my own projects, neither in larger projects I worked on. So, I'd say common sense and code review are sufficient.00:31:42 Q: So, what do you usually look at in code review for test code?00:31:49 A: Usually just whether it makes sense the way how a person writes them. See if they're trying to cover some specific cases or we think that it’s enough. If it's a test for a bug that we are trying to fix, then it´s a different thing so we'll just see whether it's the same way to catch the bug.00:32:26 A: Also, one thing about Jet Brains is we have a very flat structure. Usually people just are very much responsible for the way things work in their area of responsibility rather than in a pool of in any age stuff. It's not uncommon that you are the only person, not ever but, who cares about the way is implemented.00:33:10 Q: Yeah. It's also the case at the place I work at.00:33:20 Q: It also always depends in what context you are testing because maybe it gets very different if you are doing security testing or you are testing functionalities of a web service or whatever. So it's very difficult to generalize the effectiveness of a test.00:33:47 A: So what would be the goal of the thesis? Or would you like them to produce guidelines for more effective testing or would it be like to that there's your estimate.00:33:59 A: [explanation of the thesis goal and wrap up]