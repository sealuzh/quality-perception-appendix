Transcript: Developer Interview #5(translated transcript)00:00:13 Q: To start with some demographic questions: Can you briefly describe your experience as a developer and also as an employed developer?00:00:24 A Sure. I haven't been in development for that long on paper, but I've been involved in many projects. I've been working in development since 2017 and in IT since 2013. Before that, I was more involved in project management or data design, especially in refactoring topics. That was definitely a bigger project at that time, but I've been really involved in development since 2017, mainly in Java, and lately I've also been increasingly involved with Angular, TypeScript, JavaScript and occasionally with completely different things like SAP. But, if I were to ask myself which technologies, I have worked with most, I would say more in the direction of Java or now also increasingly in the front-end area JS, React, Angular. That's a short summary. What might make it interesting for me is that I also had a lot to do with developing algorithms in the beginning of the project. I used to work on the development of the simulation software, which was technologically not so interesting but was done in Java. Maybe you wouldn't do that anymore today, but it was very interesting from an algorithm point of view. [...]00:02:51 Q: And finally, what is your experience in software testing, and did you last write a unit test?00:02:58 A: Yesterday. Testing is good, as I said I worked both in the frontend and backend. With frontend testing I was very busy in the last project. There I partly wrote tests for other developers as well. If you would ask me now, I did a lot of frontend and backend testing.00:03:36 A: [...]00:05:54 Q: Do you have a minimum of test coverage upon committing? Or do you not look at the test coverage at all?00:06:02 A: It differs, some customer had 80% test coverage in the frontend. That's not bad I would say, so it wasn't perfect, many people want 90%. What is your experience?00:06:24 Q: Many have similar requirements such as 80%, that’s what I experienced thus far.00:06:24 A: Our current customer also has a minimum requirement of 80%.00:06:38 Q: Do you also show the test coverage to the customer? Because maybe they don’t know how to interpret it and then panic if it is not 100%.00:07:00 A: This is a very good point, especially if you have a lot of boiler plate code, then it makes no sense to test it. Then you automatically have a lower test coverage. This is a very good point.00:07:14 A: To be honest, I haven't thought about it, of course it makes sense, but I think he's already checking it out. The focus is still on functionality, of course. But what comes out of that, especially for maintenance purposes and so on, it's important that you test extensively.00:07:50 Q: Can you describe your typical process of writing new tests?00:08:02 A: Optimally, of course, what I always liked was Test-Driven Development, which we used in a project before. Sure, first you go through the requirements, then you look what kind of cases are in it, what are the ranges of values, that is always very important, are there any exceptions, so what are the requirements in the end and then you write the test. If you have that, then you can actually start developing. Most of the time it was always like that with me, which shouldn't be, but most of the time you add certain cases while you are developing that you might not have considered before. It shouldn't be like that, it's not a nice way to go about it, but it's convenient. It's mainly attributed to the development, to the development model or to the agile model. So, my experience is perhaps not formulated theoretically, with safety-critical applications you often have that you have already defined everything in advance, including all the cases, and then something changes. But in my development department you will always think of something afterwards.00:10:04 Q: How do you know if you have covered all cases? Do you look at a certain metric? Or do you go by guts feeling?00:10:21 A: Yes, often according to my gut feeling. It may sound stupid, but gut feeling is always a piece of experience. That's what makes up professional experience somehow. Well, I would say a lot of experience, metrics would be good, if I would use it more often but in the end it's the experience.00:10:48 Q: Do you also look at metrics such as coverage?00:11:28 A: Yes, at the very last when you work with Sonar, you will notice it.00:11:29 Q: Sonar is useful, do you also use it regularly?00:11:44 A: Yeah, I was in charge of it in a project. But that always implies that everyone obeys the programming rules, but in practice...00:12:02 Q: How serious do you use it? I guess it often depends on the team size?00:12:11 A: Yes, definitely, for the coordination, of course, but at the very beginning we were only a team of 3 people and there we had SonarQube. However, this was also driven by the customer, because he had his own template, which goes beyond the rules of Sonar/ the general Java rules. And we used that, and the customer had an overview. Size I think Sonar can definitely help, no question. But in the end, it depends on your code ... If you have the specific requirement to do it that way, then Sonar is definitely good. I don't know that many developers who appreciate it.00:14:03 A: I find it very useful. Definitely. You don't have to go by everything directly. Especially a lot of things that are clear for developers, but like everywhere else you forget one or the other thing. You look at it for yourself and therefore it's a good control. Because in the end you can let it run locally. In the end it's cool if you can somehow catch it before you push it.00:14:56 Q: Do you have certain guidelines you adhere to when creating unit tests? Or do you have defined testing patterns?00:15:18 A: There is certainly one other guideline, but I do not know it yet. I could imagine that there are certain conventions that are perhaps not yet recorded in the Wiki, for example conventions for better readability.00:16:13 Q: Could you please describe your procedure upon test failure?00:16:35 A: It really depends, you mean when I didn’t change anything in the code and a test fails?00:16:43 Q: Yes, for example.00:16:45 Q: Or maybe how do you know what is wrong and what you have to do in order to fix the issue?00:17:01 A: From the logs, you could say that. It depends, of course, if I'm in the middle of development and my test fails, then I look through my own code, I know roughly what I've done. When I see the message what has failed, then I might know approximately where to look for and if not, I'll look for it on the Internet for very special cases. With time you will see what you have to work on. If it's some kind of code that has already been checked in, it shouldn't happen with all the mechanisms (Maven, Jenkins, TsLint etc.) because they have been played through before. [...]00:18:20 A: The first thing I really do is look at the logs, unless it is so obvious that I see it immediately, such as a typo. But mostly the logs or the console, then off I go. Then there are also cases where it goes through locally, so the tests and then on our Jenkins not, you have to look at the logs of Jenkins, of course. I wouldn't even know if you have another chance to get the information. [...] In principle, testing is based on an expected behavior or a realistic behavior, which is not the case in production code. 00:20:41 Q: How many edge cases do you usually cover in a single test case?00:21:20 A: A [test] method should test exactly one thing in principle. But especially with such simple things like String [Input] it can happen that I use many asserts into a single test. But I don't think it's the most beautiful variant, but it is practical.00:22:07 Q: Well there are always benefits or drawbacks, it may be faster to write the tests that way. 00:22:31 A: And above all you might need to get to the point, e.g. if you query any input field, you have to reference it somehow in a different way and that's a lot of lines of code to get there. Of course, there is the argument, that there are also many frameworks that do pre-processing which may also be the most beautiful variant, but in practice ... I should do it more often. But with such simple things it can happen that I put multiple Asserts. But "best practice" is a method to test exactly one thing.00:23:38 Q: We already started analysing unit test in detail, especially what you deem important in a unit test. What makes for a good or effective unit test in your opinion?00:24:04 A: First, of course, that it does what it is supposed to/ what he is named to do. It is always very important to carefully chose the name of a test. Especially if you have a lot of tests, it should be easy to read, that is important. Of course, it does what is required, that you take the right "matchers". But in general, an effective test is to cover a lot of test cases with as few lines of code as possible.00:25:46 Q: So, would a small, compact test be more effective as opposed to one that requires a lot of setup?00:25:57 A: That's just the question of maintainability, you have to find a good balance. Sure, you always say as little code as possible, readable is always good and maintainable. But especially if you have a lot of cases, it might make sense to break it down a bit more finely, then maybe you can adjust it later. This is often the question of effort, you could say. I think an effective test is generally to cover a lot with as little effort as possible. It should not exceed a certain number of lines, just that it is readable. If it's a relatively long test, I always have the impression that you're testing a lot of things, or that you're not going through the tests step by step enough, but that you somehow put a lot of things into one test. Then we are back to the principle that only one thing should be tested per test. Then it always smells a lot. [...]00:28:06 Q: Do you also look at how useful a test is in determining faults in the production code i.e. in refactoring?00:29:22 A: Yes, normally it fails then or even before that if I set it up well.00:30:33 Q: Do you also have certain production code patterns that improves the testability of the system? For example, do you make use of pre/post conditions?00:30:45 A: Yes, there are certain requirements from the environment already. For example, if you have a different profile and so on or generally certain prerequisites. It really depends on the application.00:31:43 Q: Do you use any other indicators for test effectiveness? So far, we discussed readability and maintainability.00:31:43 A Yes, of course, next comes the adaptability/fragility of a test.00:32:01 Q: But readability is still the most important point for you?00:32:01 A: Yes of course, readability and that it also does what the test is supposed to. Those are the things I pay special attention to. I'm going to take a quick look at my code...00:32:39 Q: Of course, go ahead.00:32:39 A: What do others in the study say about it?00:32:45 Q: Very similar opinions to yours. Many Sehr ähnlich, many say the readability and maintainability as you say it has an indirect influence in the whole process. Then also the ability to locate and fix faults. And then also the correctness of the input. Then there is perhaps also flakiness, do you run the tests several times to make sure that it always runs correctly?00:33:32 A: To make sure that there is no issue with the test itself?00:33:32 Q: Yes exactly, sometimes there might be some logic in a unit test.00:33:57 A: Well if you start testing your tests, then…00:34:20 Q: Then there are also test smells. Do you also think that could be an important factor?00:34:36 A: Yeah, definitely. I would also include them, because in the end it's code and especially in the testing area you automatically have many dependencies in there, that can backfire. So, I would definitely consider code smells as well. For me, it's part of the readability, because if I have it in a familiar structure, like everywhere else, then I can read it easier and faster and code smells are not unfamiliar. We all make mistakes and produce all code smells, but it is then often easy to read.00:35:43 Q: Then you often need to compare the benefits to the drawbacks.00:36:00 A: Would you be able to judge the effectiveness of your unit test based on the features we mentioned?00:36:33 A: Yes, absolutely. I can already see whether a test is sustainable and adaptable and that as many cases as possible are covered. [...]00:37:39 Q: Then maybe back to the readability. What do you look for in your code to judge the readability of your tests? Do you look at naming or do you always have a well-defined test structure?00:38:28 A: Yes, it has to be structured "intuitively", so that, for example, the things you do before the test are not done at the bottom of the case, but that you can read the test well, that what happens first is somehow the first thing and then it is processed. Of course, the naming is important or very important. It can make sense to nest tests but be very careful. Because as soon as you nest something, you automatically create dependencies that may not be present in the production code. Then you get bugs there again. These are special cases, but I still wouldn't nest them too much, not even for readability. Things like that, the naming, the input is right, what goes into the method, that's very important to look at. Especially if you are in the object-oriented Java, or you see that somehow it is not possible to define the data types properly, also that you intercept a lot and so on.00:40:25 Q: Great, so that was it. Do you have anything to add that we didn’t discuss? Or any comments on the interview.